apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: aether
spec:
  replicas: 2
  serviceAccountName: prometheus
  serviceMonitorSelector:
    matchLabels:
      release: aether
  podMonitorSelector:
    matchLabels:
      release: aether
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2
      memory: 4Gi
  ruleSelector:
    matchLabels:
      app: aether-prometheus-rules
  additionalScrapeConfigs:
    name: prometheus-additional-scrape
    key: scrape-configs.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
spec:
  selector:
    prometheus: aether
  ports:
    - name: web
      port: 9090
      targetPort: web
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: aether-rules
  labels:
    app: aether-prometheus-rules
spec:
  groups:
    - name: trading-kpis
      rules:
        - record: trading:orders:rate5m
          expr: sum(rate(order_gateway_orders_total[5m]))
        - alert: TradingVolumeDrop
          expr: sum(rate(order_gateway_filled_notional_usd[15m])) < 1000
          for: 10m
          labels:
            severity: critical
          annotations:
            summary: Trading volume dropped below threshold
            description: Investigate connectivity to exchanges.
    - name: fee-monitoring
      rules:
        - alert: ExcessiveFeeSpend
          expr: sum(increase(order_gateway_fee_spend_usd[1h])) > 500
          for: 15m
          labels:
            severity: warning
          annotations:
            summary: Fee spend exceeding normal bounds
            description: Review routing strategies.
    - name: drift-monitoring
      rules:
        - alert: PricingDriftHigh
          expr: abs(avg_over_time(pricing_service_mid_price_delta[5m])) > 0.5
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Market data drift detected
            description: Check data sources.
    - name: circuit-breakers
      rules:
        - alert: CircuitBreakerEngaged
          expr: max_over_time(order_gateway_circuit_breaker_engaged[1m]) > 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: Circuit breaker engaged
            description: Verify risk thresholds.
    - name: slos
      rules:
        - record: trading:latency:availability
          expr: 1 - (sum(rate(order_gateway_request_errors_total[5m])) / sum(rate(order_gateway_requests_total[5m])))
        - alert: oms_latency_slo_breach
          expr: |
            histogram_quantile(0.99, sum(rate(oms_order_latency_seconds_bucket[5m])) by (le)) > 0.12
          for: 10m
          labels:
            severity: critical
            slo_target: "p99<=0.150s"
          annotations:
            summary: OMS latency approaching 150 ms SLO budget
            description: Investigate exchange connectivity or OMS backpressure.
            runbook: docs/runbooks/exchange_outage.md
            slo_reference: docs/slo.md#oms-latency
        - alert: ws_latency_slo_breach
          expr: |
            histogram_quantile(0.99, sum(rate(ws_delivery_latency_seconds_bucket[5m])) by (le)) > 0.25
          for: 15m
          labels:
            severity: warning
            slo_target: "p99<=0.300s"
          annotations:
            summary: WebSocket delivery latency nearing 300 ms SLO
            description: Validate gateway consumers and cache warmers.
            runbook: docs/runbooks/websocket_desync.md
            slo_reference: docs/slo.md#websocket-ingest-latency
        - alert: kill_switch_slo_warning
          expr: max_over_time(kill_switch_response_seconds[5m]) > 45
          for: 1m
          labels:
            severity: critical
            slo_target: "response<=60s"
          annotations:
            summary: Kill-switch response time exceeded 45 s warning threshold
            description: Confirm automation is halting order flow fast enough.
            runbook: docs/runbooks/kill_switch_activation.md
            slo_reference: docs/slo.md#kill-switch-response
        - alert: model_canary_promotion_slow
          expr: |
            (sum(increase(model_canary_promotion_duration_minutes_count[24h])) > 0)
            and ignoring(job)
            (sum(increase(model_canary_promotion_duration_minutes_bucket{le="30"}[24h]))
             < sum(increase(model_canary_promotion_duration_minutes_count[24h])))
          for: 5m
          labels:
            severity: warning
            slo_target: "p95<=45m"
          annotations:
            summary: Consecutive canary promotions exceeding 30 minute alert threshold
            description: Inspect canary validation and feature pipelines.
            runbook: docs/runbooks/model_rollback.md
            slo_reference: docs/slo.md#model-canary-promotion
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-additional-scrape
  labels:
    app: prometheus
    release: aether
data:
  scrape-configs.yaml: |
    - job_name: fastapi
      honor_labels: true
      kubernetes_sd_configs:
        - role: pod
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          action: keep
          regex: order-gateway|pricing-service
        - source_labels: [__meta_kubernetes_pod_container_port_name]
          action: keep
          regex: http
    - job_name: kafka
      static_configs:
        - targets: ['bootstrap.kafka:9092']
