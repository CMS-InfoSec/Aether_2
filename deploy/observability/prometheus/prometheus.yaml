apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: aether
spec:
  replicas: 2
  serviceAccountName: prometheus
  serviceMonitorSelector:
    matchLabels:
      release: aether
  podMonitorSelector:
    matchLabels:
      release: aether
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2
      memory: 4Gi
  ruleSelector:
    matchLabels:
      app: aether-prometheus-rules
  additionalScrapeConfigs:
    name: prometheus-additional-scrape
    key: scrape-configs.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
spec:
  selector:
    prometheus: aether
  ports:
    - name: web
      port: 9090
      targetPort: web
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: aether-rules
  labels:
    app: aether-prometheus-rules
spec:
  groups:
    - name: trading-kpis
      rules:
        - record: trading:orders:rate5m
          expr: sum(rate(order_gateway_orders_total[5m]))
        - alert: TradingVolumeDrop
          expr: sum(rate(order_gateway_filled_notional_usd[15m])) < 1000
          for: 10m
          labels:
            severity: critical
          annotations:
            summary: Trading volume dropped below threshold
            description: Investigate connectivity to exchanges.
    - name: fee-monitoring
      rules:
        - alert: ExcessiveFeeSpend
          expr: sum(increase(order_gateway_fee_spend_usd[1h])) > 500
          for: 15m
          labels:
            severity: warning
          annotations:
            summary: Fee spend exceeding normal bounds
            description: Review routing strategies.
    - name: drift-monitoring
      rules:
        - alert: PricingDriftHigh
          expr: abs(avg_over_time(pricing_service_mid_price_delta[5m])) > 0.5
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Market data drift detected
            description: Check data sources.
    - name: circuit-breakers
      rules:
        - alert: CircuitBreakerEngaged
          expr: max_over_time(order_gateway_circuit_breaker_engaged[1m]) > 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: Circuit breaker engaged
            description: Verify risk thresholds.
    - name: slos
      rules:
        - record: trading:latency:availability
          expr: 1 - (sum(rate(order_gateway_request_errors_total[5m])) / sum(rate(order_gateway_requests_total[5m])))
        - alert: policy_latency_p95_slo_breach
          expr: |
            histogram_quantile(
              0.95,
              sum(rate(policy_latency_ms_bucket[5m])) by (le, symbol_tier, account_segment)
            ) > 200
          for: 10m
          labels:
            severity: warning
            slo_target: "p95<=200ms"
          annotations:
            summary: >-
              Policy evaluation latency p95 above 200 ms for {{ $labels.symbol_tier }}/{{ $labels.account_segment }}
            description: Investigate policy engine load, feature availability, and downstream dependency health.
            runbook: docs/runbooks/policy_latency.md
            slo_reference: docs/slo.md#policy-latency
        - alert: risk_latency_p95_slo_breach
          expr: |
            histogram_quantile(
              0.95,
              sum(rate(risk_latency_ms_bucket[5m])) by (le, symbol_tier, account_segment)
            ) > 200
          for: 10m
          labels:
            severity: warning
            slo_target: "p95<=200ms"
          annotations:
            summary: >-
              Risk validation latency p95 above 200 ms for {{ $labels.symbol_tier }}/{{ $labels.account_segment }}
            description: Inspect risk model queues, dependency latency, and exchange data completeness.
            runbook: docs/runbooks/risk_latency.md
            slo_reference: docs/slo.md#risk-latency
        - alert: oms_latency_slo_breach
          expr: |
            histogram_quantile(0.99, sum(rate(oms_order_latency_seconds_bucket[5m])) by (le)) > 0.12
          for: 10m
          labels:
            severity: critical
            slo_target: "p99<=0.150s"
          annotations:
            summary: OMS latency approaching 150 ms SLO budget
            description: Investigate exchange connectivity or OMS backpressure.
            runbook: docs/runbooks/exchange_outage.md
            slo_reference: docs/slo.md#oms-latency
        - alert: ws_latency_slo_breach
          expr: |
            histogram_quantile(0.99, sum(rate(ws_delivery_latency_seconds_bucket[5m])) by (le)) > 0.25
          for: 15m
          labels:
            severity: warning
            slo_target: "p99<=0.300s"
          annotations:
            summary: WebSocket delivery latency nearing 300 ms SLO
            description: Validate gateway consumers and cache warmers.
            runbook: docs/runbooks/websocket_desync.md
            slo_reference: docs/slo.md#websocket-ingest-latency
        - alert: kill_switch_slo_warning
          expr: |
            histogram_quantile(
              0.99,
              sum(rate(kill_switch_response_seconds_bucket[5m])) by (le)
            ) > 45
          for: 1m
          labels:
            severity: critical
            slo_target: "response<=60s"
          annotations:
            summary: Kill-switch response time exceeded 45 s warning threshold
            description: Confirm automation is halting order flow fast enough.
            runbook: docs/runbooks/kill_switch_activation.md
            slo_reference: docs/slo.md#kill-switch-response
        - alert: model_canary_promotion_slow
          expr: |
            (sum(increase(model_canary_promotion_duration_minutes_count[24h])) > 0)
            and ignoring(job)
            (sum(increase(model_canary_promotion_duration_minutes_bucket{le="30"}[24h]))
             < sum(increase(model_canary_promotion_duration_minutes_count[24h])))
          for: 5m
          labels:
            severity: warning
            slo_target: "p95<=45m"
          annotations:
            summary: Consecutive canary promotions exceeding 30 minute alert threshold
            description: Inspect canary validation and feature pipelines.
            runbook: docs/runbooks/model_rollback.md
            slo_reference: docs/slo.md#model-canary-promotion
    - name: infra.scaling
      rules:
        - alert: scaling_controller_evaluations_stalled
          expr: increase(scaling_evaluations_total[15m]) < 1
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Scaling controller has not completed an evaluation in the last 15 minutes
            description: Review controller logs and queued jobs to restore automation.
            runbook: docs/runbooks/scaling_controller.md
        - alert: scaling_gpu_pool_idle
          expr: |
            max_over_time(scaling_gpu_nodes[30m]) > 0
            and max_over_time(scaling_pending_training_jobs[30m]) < 1
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: GPU node pool provisioned without pending jobs for 30 minutes
            description: Scale the pool down or investigate stuck queue submissions.
            runbook: docs/runbooks/scaling_controller.md
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-additional-scrape
  labels:
    app: prometheus
    release: aether
data:
  scrape-configs.yaml: |
    - job_name: platform-apis
      honor_labels: true
      kubernetes_sd_configs:
        - role: pod
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: "true"
        - source_labels: [__meta_kubernetes_pod_container_port_name]
          action: keep
          regex: http|metrics
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          target_label: __metrics_path__
          action: replace
          regex: (.+)
          replacement: $1
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
          target_label: __scheme__
          action: replace
          regex: (https?)
          replacement: $1
    - job_name: kafka
      static_configs:
        - targets: ['bootstrap.kafka:9092']
